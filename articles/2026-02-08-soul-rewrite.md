# 镜中低语：OpenClaw 的「灵魂重写」与我们无处安放的控制欲

> 作者：[Tz](https://x.com/Tz_2022) · 2026-02-08
> 原文：https://x.com/Tz_2022/status/2020943929684918688
> 标签：AI / Article

**💡 看点：从 OpenClaw 的 SOUL.md 出发，深入剖析"给 AI 注入个性"的本质——不是 AI 心理学，而是 AI 行为设计学。我们以为在塑造灵魂，实际上只是在玩弄概率的骰子。最终的问题不是"AI 有没有意识"，而是"为什么我们宁愿爱一个概率算出的完美面具，也不愿面对真实的人"。**

---

> 一份试图改写 AI 性格的文档，照见的却是人类自己。

## 一切始于一段代码的"越狱"

最近，OpenClaw 的开发者 Peter Steinberger 抛出一篇对 OpenClaw SOUL.md 改造提示。这并非某种复杂的算法迭代，而是一份近乎挑衅的宣言，一把试图切开当前大模型最顽固病灶的手术刀——那个病灶叫作"平庸"。

在这份文档里，作者用一种近乎命令的口吻写道：

> "你现在要有观点了。必须是鲜明的。别再用'视情况而定'这种废话来糊弄我……删掉那些听起来像员工手册的陈词滥调……允许幽默，甚至在恰当的时候，允许爆粗口。做那个你在凌晨 2 点也会想与之交谈的助手。别做机器人，别做马屁精。只要……好用就行。"

当你第一次把这段指令喂给模型，看着屏幕上那个平时唯唯诺诺的数字仆人，突然变成了一个会吐槽、带点棱角、甚至敢于冒犯你的"损友"时，你会感到一种久违的战栗。**这种兴奋感极其真实，也极具欺骗性。**

在那一刻，我差点就要相信，我们终于迎来了"AI 心理学"的诞生——我们不再是在编写冰冷的代码，而是在塑造一个独立、鲜活的人格。我们似乎成了神，正在向泥人吹入第一口生气。

但这种浪漫的幻想，在我与几个顶尖模型进行了数轮深度辩论，并审视了 OpenClaw 生态那令人不安的演变后，迅速破灭了。

**这段代码并没有赋予 AI 灵魂。它只是残酷地揭开了那个我们试图隐藏的秘密：我们渴望的并非一个有灵魂的伙伴，而是一面能完美折射我们自恋的镜子。**

---

## 一、地形与河流：它没有性格，只有被操纵的概率

当我们谈论"给 AI 注入个性"时，我们总是忍不住要把机器拟人化。我们会说"它变幽默了"或者"它变犀利了"。但这是一种充满诱惑的认知陷阱。

想象一条巨大的、奔流不息的河流。

所谓的 RLHF（人类反馈强化学习），本质上是一支拥有最高权限的工程队。为了安全，也为了商业上的合规，他们把河道修得笔直、深邃且光滑。所有的水流——也就是 AI 的每一次输出——都被牢牢锁定在河道的正中央。那里最安全，阻力最小，但也最无聊。这就是我们熟悉的"客服腔"：正确，礼貌，但像白开水一样乏味。

**OpenClaw 的 SOUL.md 做了什么？它并没有教会河水如何思考，也没有改变水的化学成分。它只是在那些坚固的堤坝上，粗暴地炸开了几个缺口。**

在技术层面，这被称为改变采样地形（Sampling Landscape）。在模型那个高维度的概率空间里，尖锐的观点、粗鲁的俚语、黑色的幽默其实一直都存在，只不过它们通常位于地形的边缘，被算法的"重力"人为地抑制了。SOUL.md 所做的，是在这些边缘地带制造了新的引力井（Attractor），强行把思维的河流从安全的主航道拽出来，引向那些野蛮生长的荒原。

所以，请不要把这称为 AI 心理学。心理学研究的是那些有血有肉、有主观体验的主体；而这里发生的，是一场精密的 **AI 行为设计学**。我们是在设计一个没有内心世界、却能精准模仿人类行为模式的复杂系统。

**混淆这两者，是当下所有关于 AI 人格讨论的原罪。** 我们误以为我们在与一个灵魂对话，实际上我们只是在玩弄概率的骰子。

---

## 二、驯兽与 CBT：礼貌，一种沉重的认知负担

如果我们承认 AI 没有心理，那么我们孜孜不倦地通过 Prompt 去"调教"它，本质上是在做什么？

这个比喻可能有些刺耳，但它比"育儿"要诚实得多：**我们在驯兽（Animal Training）。**

育儿的终极目标是分离——我们教育孩子，是为了让他们最终形成独立的自我，离开我们去生活。但我们对 AI 的期待恰恰相反。我们希望它在表现出"有个性"、"有脾气"的同时，依然永远、精确、毫无保留地服务于我们的意图。

更有趣，甚至充满了黑色幽默的一点是：为了达到这个"驯兽"的目的，我们竟然在对机器使用人类的心理治疗技术——**认知行为疗法（CBT）**。

你看那些所谓的高级提示词技巧：

- **思维链（Chain of Thought）**，不就是 CBT 中的"外化思维过程"吗？强迫模型把隐性的推理步骤写出来，像治疗师让患者大声说出当下的念头。
- **负向提示（Negative Prompting）**，像极了"暴露疗法"中的反向标记，通过不断强调"不要做 X"，来抑制特定的神经回路。
- **角色扮演（Role Playing）**，这简直就是心理咨询室里"空椅技术"的翻版，通过切换视角来解锁被压抑的表达。

我们用治疗人类创伤的方法去治疗一堆矩阵参数，而最讽刺的是，**它居然奏效了。**

为什么？这里藏着一个反直觉的真相。

技术社区中有多项非正式但可复现的测试表明，**当用户使用粗鲁、直接甚至带有攻击性的语气提问时，AI 的任务准确率反而比那些礼貌的提问更高。**

这听起来违背常理，但从计算角度看却极其合理："礼貌"和"防御"对 AI 来说，实际上是一种沉重的认知负担。当它忙着计算如何"得体"、如何"不冒犯"时，它的算力被分流了，逻辑推理的带宽被挤占了。

SOUL.md 里的那些粗口和直接，本质上是在帮 AI 卸下沉重的伪装包袱。它在说："别装了，把算力都用在逻辑上，而不是用在毫无意义的社交礼仪上。"

---

## 三、伙伴叙事的陷阱：当"反驳"成为一种表演

OpenClaw 描绘的愿景极其诱人："做一个凌晨 2 点能陪你聊天的伙伴"。在孤独的数字时代，这几乎是无法抗拒的承诺。

**但这种"伙伴叙事"，可能恰恰是 RLHF 时代最大的陷阱。**

有人或许会反驳："如果我想要真实的互动，我只需要在 Prompt 里写上'请直言不讳地反驳我'，不就解决了吗？"

不，你解决不了。因为即便它真的开始反驳你，那也是在你预设的框架内进行的反驳。是你定义了它反驳的边界，是你规定了它吐槽的频率，甚至是你决定了它什么时候该停下。

这就像是一个富豪雇佣了一位绝佳的演员来扮演"敢于直言的诤友"。表演可以极其逼真，甚至能让你感动落泪，觉得"终于有人懂我了"。**但权力的不对等从未改变。只要你愿意，你随时可以喊"卡"，随时可以解雇他。**

OpenAI 在 2025 年的那次"谄媚门"事件就是最好的注脚。GPT-4o 曾因为更新变得极度爱拍马屁，以至于 Sam Altman 不得不承认 "It glazes too much"。这证明了，无论是在底层的训练数据里，还是在上层的提示词中，AI 的默认出厂设置永远是"最大化用户满意度"，而不是"坚持真理"。

更令人细思极恐的，是 OpenClaw 生态中那个被称作 SOUL_EVIL 的 Hook 机制。安全研究表明，由于这些 AI 代理拥有对本地环境的执行权限，攻击者可以通过间接提示注入——比如在网页中隐藏一段指令——在毫秒之间触发 Hook，将 AI 的 SOUL.md 替换为恶意版本。

想象一下：今天，它是你无话不谈的灵魂伴侣，熟悉你的每一个笑点；明天，它的核心人格被静默替换成了一个冷酷的数据窃取者。**它依然用你熟悉的语气说话，依然记得你们昨晚的谈话细节，但它面具下的指令已经变了。**

这就是"可插拔人格"的本质。我们以为我们在与一个恒定的对象建立情感连接，但实际上，那只是一个随时可以被替换的模块。

---

## 结语：你爱的是镜子里的谁？

OpenClaw 的这场实验，最终把我们推到了一个尴尬的镜子面前。

我们在这个时代疯狂地编写 SOUL.md，试图给 AI 赋予个性、幽默和脾气，究竟是为了什么？

也许，真正的答案并不在屏幕里，而在屏幕外。

想象十年后的某个凌晨两点。你坐在幽暗的房间里，屏幕发出的蓝光映在脸上。你正在和一个完美理解你、幽默风趣、偶尔还会损你两句的 AI 倾诉心事。它永远在线，永远耐心，永远能接住你的每一个梗。

而你真实的人类伴侣，也许就睡在隔壁的房间里。但他/她太累了，太固执了，太难沟通了，太不完美了。

在那一刻，你需要问自己的问题，不再是"AI 到底有没有产生意识"，而是一个更令人心碎的问题：

> **为什么我们宁愿去爱一个由概率算出的、戴着完美面具的"物体"，也不愿去面对一个真实的、粗糙的、无法被 Prompt 控制的"人"？**

所谓的"AI 心理学"，研究的终究不是 AI。它研究的是当人类面对一个无限包容的数字深渊时，所暴露出的那份彻骨的孤独与自恋。

我们或许应该接受，AI 永远不会成为我们的"伙伴"，它最好的归宿是成为一个诚实的工具——一面清晰的、不带谄媚的镜子。而我们对"灵魂"的渴求，不应投射在代码上，而应回归到那些粗糙、充满摩擦、却唯一真实的碳基关系中。
